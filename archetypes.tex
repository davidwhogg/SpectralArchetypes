\documentclass[12pt]{article}
\usepackage{amssymb,amsmath}

\newcommand{\ampj}{p_j}
\newcommand{\ampij}{q_{ij}}
\newcommand{\chisq}{\chi^2}
\newcommand{\chisqij}{\chisq_{ij}}
\newcommand{\Mvector}[1]{\mathbf{#1}}
\newcommand{\point}{\Mvector{s}}
\newcommand{\spectrumi}{\point_i}
\newcommand{\archetypej}{\Mvector{a}_j}
\newcommand{\xxj}{\Mvector{x}_j}
\newcommand{\Mmatrix}[1]{\mathbb{#1}}
\newcommand{\covari}{\Mmatrix{C}_i}
\newcommand{\covarj}{\Mmatrix{Q}_i}
\newcommand{\inverse}[1]{{#1}^{-1}}
\newcommand{\invcovari}{\inverse{\covari}}
\newcommand{\transpose}[1]{{#1}^{\mathsf{T}}}
\newcommand{\minover}[1]{\min_{#1}\,}

\begin{document}

Assume that the data consist of $N$ galaxy spectra $\spectrumi$, where
$i$ indexes the galaxy, and where each spectrum is a column vector
(meaning, in this case, ordered list formatted as a single-column
matrix) of $M$ pixel values on some standard wavelength grid (the same
wavelength grid for every spectrum).  Assume that for each spectrum
$\spectrumi$ we also know that the measurement is contaminated by
purely gaussian noise, and that the noise variances and covariances
are described accurately by a $M\times M$ covariance matrix $\covari$
(or, equivalently, its inverse $\invcovari$).  These covariance
matrices are different for each spectrum in general.

We want to ``model'' these $N$ spectra as being generated by a
distribution $f(\point)$ in the $M$-dimensional data space that is a
sum of $k$ delta functions located at positions $\archetypej$, or
\begin{equation}
f(\point) = \sum_{j=1}^{k} \ampj\,\delta(\point-\archetypej) \quad ,
\end{equation}
where the $\ampj$ are a set of amplitudes that sum to unity
\begin{equation}
1 = \sum_{j=1}^{k} \ampj \quad .
\end{equation}
(The above is not quite right because we allow an amplitude $\ampij$
to vary in what follows below.)

If the noise is gaussian, the correct measure of ``distance'' between
a spectrum $\spectrumi$ and an archetype $\archetypej$ is $\chisqij$
\begin{equation}
\chisqij = \transpose{(\spectrumi-\archetypej)}
           \cdot\invcovari\cdot(\spectrumi-\archetypej) \quad ,
\end{equation}
where we have assumed that the spectra and the archetypes are all
normalized in some clever way.  Probably better is to renormalize
spectrum-by-spectrum
\begin{equation}
\chisqij = \transpose{(\spectrumi-\ampij\,\archetypej)}
           \cdot\invcovari\cdot(\spectrumi-\ampij\,\archetypej) \quad ,
\end{equation}
where the amplitude $\ampij$ is the best-fit ($\chisqij$-minimizing)
value for each spectrum--archetype pair.  The ``best fit'' archetype
$\archetypej$ for spectrum $\spectrumi$ is the archetype that
minimizes $\chisqij$.  We denote the best-fit archetype index $j=J_i$.

The overall log likelihood of the $N$ spectra $\spectrumi$ given the
$k$ archetypes $\archetypej$ is proportional to the negative of the
total chi-squared sum for all the spectra under each spectrum's
best-fit archetype, or
\begin{equation}
\chisq = \sum_{i=1}^{N} \minover{j}\chisqij
       = \sum_{i=1}^{N}\sum_{j=1}^{k} \delta(j-J_i)\,\chisqij \quad ,
\end{equation}
where the delta-function selects the best-fit archetype.  This
($\chisq$) is the scalar objective we use to compare $k$-archetype
models at fixed $k$ (in the absence of an informative prior).

Now, how do we go about minimizing the scalar objective $\chisq$?
There is a generalization of the $k$-means algorithm that proceeds as
follows.  Imagine that you have a first-guess set of archetypes
$\archetypej$.
\begin{itemize}
\item For each archetype $\archetypej$, take the subset of spectra
$\spectrumi$ for which $\archetypej$ is the best-fit model of
$\spectrumi$, and replace the archetype $\archetypej$ with the
inverse-covariance-weighted mean (see below) of that subset.
\item Re-compute the best-fit amplitudes $\ampij$ and
spectrum--archetype relations $J_i$.
\item Iterate to convergence (that is, no more changes in $J_i$ for any $i$).
\end{itemize}
In case you were wondering, the inverse-covariance-weighed mean is
given by (I think---it is late---I am guessing):
\begin{equation}
\archetypej \leftarrow \covarj\cdot\xxj \quad ,
\end{equation}
where
\begin{equation}
\covarj = \inverse{\left[\sum_{i=0}^N
                         \delta(j-J_i)\,\ampij\,\invcovari\right]} \quad ,
\end{equation}
\begin{equation}
\xxj = \sum_{i=0}^N \delta(j-J_i)\,\invcovari\cdot\spectrumi \quad ,
\end{equation}
and the delta-functions select the set of spectra for which the
best-fit archetype is $\archetypej$.  If replacement by this weighted
mean reduces the chi-squared contribution for the spectra that are
best-fit by $\archetypej$, then I think we can prove that the full
update always leads to convergence to a local minimum.

\end{document}
